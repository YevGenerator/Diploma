{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T00:32:46.390485Z",
     "start_time": "2025-11-05T00:28:56.530998Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_00000 | GT=54 | Pred=54 | ✅\n",
      "img_00001 | GT=4052 | Pred=40552 | ❌\n",
      "img_00002 | GT=749 | Pred=748 | ❌\n",
      "img_00003 | GT=4135 | Pred=4888 | ❌\n",
      "img_00004 | GT=5 | Pred=5 | ✅\n",
      "img_00005 | GT=94 | Pred=94 | ✅\n",
      "img_00006 | GT=4111 | Pred=41111 | ❌\n",
      "img_00007 | GT=5348 | Pred=5348 | ✅\n",
      "img_00008 | GT=8416 | Pred=347 | ❌\n",
      "img_00009 | GT=44 | Pred=44 | ✅\n",
      "img_00010 | GT=1749 | Pred=1749 | ✅\n",
      "img_00011 | GT=881 | Pred=887 | ❌\n",
      "img_00012 | GT=6481 | Pred=648 | ❌\n",
      "img_00013 | GT=59 | Pred=59 | ✅\n",
      "img_00014 | GT=48 | Pred=48 | ✅\n",
      "img_00015 | GT=80293 | Pred=30293 | ❌\n",
      "img_00016 | GT=10804 | Pred=1080 | ❌\n",
      "img_00017 | GT=4 | Pred=4 | ✅\n",
      "img_00018 | GT=85511 | Pred=855111 | ❌\n",
      "img_00019 | GT=1785 | Pred=1785 | ✅\n",
      "img_00020 | GT=45064 | Pred=45064 | ✅\n",
      "img_00021 | GT=38 | Pred=38 | ✅\n",
      "img_00022 | GT=0950 | Pred=0950 | ✅\n",
      "img_00023 | GT=24 | Pred=24 | ✅\n",
      "img_00024 | GT=74686 | Pred=74686 | ✅\n",
      "img_00025 | GT=2 | Pred=2 | ✅\n",
      "img_00026 | GT=349 | Pred=848 | ❌\n",
      "img_00027 | GT=83 | Pred=833 | ❌\n",
      "img_00028 | GT=2 | Pred=8 | ❌\n",
      "img_00029 | GT=02 | Pred=88 | ❌\n",
      "img_00030 | GT=27808 | Pred=24788008 | ❌\n",
      "img_00031 | GT=324 | Pred=324 | ✅\n",
      "img_00032 | GT=30142 | Pred=30142 | ✅\n",
      "img_00033 | GT=2 | Pred=2 | ✅\n",
      "img_00034 | GT=06 | Pred=06 | ✅\n",
      "img_00035 | GT=50292 | Pred=50292 | ✅\n",
      "img_00036 | GT=87 | Pred=87 | ✅\n",
      "img_00037 | GT=44325 | Pred=4432 | ❌\n",
      "img_00038 | GT=147 | Pred=444 | ❌\n",
      "img_00039 | GT=3 | Pred=3 | ✅\n",
      "img_00040 | GT=82 | Pred=88 | ❌\n",
      "img_00041 | GT=1287 | Pred=11287 | ❌\n",
      "img_00042 | GT=3 | Pred=3 | ✅\n",
      "img_00043 | GT=20 | Pred=20 | ✅\n",
      "img_00044 | GT=2820 | Pred=2820 | ✅\n",
      "img_00045 | GT=359 | Pred=859 | ❌\n",
      "img_00046 | GT=4491 | Pred=449 | ❌\n",
      "img_00047 | GT=01 | Pred=01 | ✅\n",
      "img_00048 | GT=8136 | Pred=88836 | ❌\n",
      "img_00049 | GT=62913 | Pred=622913 | ❌\n",
      "img_00050 | GT=0 | Pred=0 | ✅\n",
      "img_00051 | GT=92 | Pred=92 | ✅\n",
      "img_00052 | GT=08060 | Pred=08060 | ✅\n",
      "img_00053 | GT=104 | Pred=104 | ✅\n",
      "img_00054 | GT=5211 | Pred=5211 | ✅\n",
      "img_00055 | GT=34 | Pred=88 | ❌\n",
      "img_00056 | GT=31527 | Pred=38527 | ❌\n",
      "img_00057 | GT=3348 | Pred=884 | ❌\n",
      "img_00058 | GT=5231 | Pred=5231 | ✅\n",
      "img_00059 | GT=82131 | Pred=8213 | ❌\n",
      "img_00060 | GT=5 | Pred=5 | ✅\n",
      "img_00061 | GT=5 | Pred=5 | ✅\n",
      "img_00062 | GT=2 | Pred=8 | ❌\n",
      "img_00063 | GT=658 | Pred=658 | ✅\n",
      "img_00064 | GT=9755 | Pred=9755 | ✅\n",
      "img_00065 | GT=144 | Pred=888 | ❌\n",
      "img_00066 | GT=06576 | Pred=06576 | ✅\n",
      "img_00067 | GT=889 | Pred=889 | ✅\n",
      "img_00068 | GT=17 | Pred=448 | ❌\n",
      "img_00069 | GT=476 | Pred=888 | ❌\n",
      "img_00070 | GT=0716 | Pred=07066 | ❌\n",
      "img_00071 | GT=319 | Pred=319 | ✅\n",
      "img_00072 | GT=05420 | Pred=85488 | ❌\n",
      "img_00073 | GT=18 | Pred=18 | ✅\n",
      "img_00074 | GT=82954 | Pred=84954 | ❌\n",
      "img_00075 | GT=9894 | Pred=9888 | ❌\n",
      "img_00076 | GT=4 | Pred=4 | ✅\n",
      "img_00077 | GT=2 | Pred=99 | ❌\n",
      "img_00078 | GT=57446 | Pred=51441 | ❌\n",
      "img_00079 | GT=4 | Pred=1 | ❌\n",
      "img_00080 | GT=14 | Pred=14 | ✅\n",
      "img_00081 | GT=5 | Pred=5 | ✅\n",
      "img_00082 | GT=2 | Pred=2 | ✅\n",
      "img_00083 | GT=66680 | Pred=66680 | ✅\n",
      "img_00084 | GT=4796 | Pred=4796 | ✅\n",
      "img_00085 | GT=70 | Pred=88 | ❌\n",
      "img_00086 | GT=7 | Pred=7 | ✅\n",
      "img_00087 | GT=18 | Pred=88 | ❌\n",
      "img_00088 | GT=245 | Pred=245 | ✅\n",
      "img_00089 | GT=446 | Pred=488 | ❌\n",
      "img_00090 | GT=14 | Pred=74 | ❌\n",
      "img_00091 | GT=89 | Pred=88 | ❌\n",
      "img_00092 | GT=1 | Pred=8 | ❌\n",
      "img_00093 | GT=22572 | Pred=12111 | ❌\n",
      "img_00094 | GT=495 | Pred=495 | ✅\n",
      "img_00095 | GT=15 | Pred=155 | ❌\n",
      "img_00096 | GT=256 | Pred=111 | ❌\n",
      "img_00097 | GT=0 | Pred=1 | ❌\n",
      "img_00098 | GT=70221 | Pred=702221 | ❌\n",
      "\n",
      "✅ Accuracy: 50.00% (50/100)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Testing_validation.ipynb (оновлена версія з GT)\n",
    "# ==============================================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# ----------------------------------------------\n",
    "# TODO: вкажіть ваші шляхи\n",
    "# ----------------------------------------------\n",
    "YOLO_MODEL_PATH = \"./runs/detect/train9/weights/best.pt\"\n",
    "CLASSIFIER_MODEL_PATH = \"./models/digit_classifier_best.keras\"\n",
    "TEST_IMAGES_DIR = \"./learning/data_number/valid/images\"\n",
    "TEST_LABELS_DIR = \"./learning/data_number/valid/labels\"\n",
    "# ----------------------------------------------\n",
    "\n",
    "# Завантаження моделей\n",
    "yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "classifier = tf.keras.models.load_model(CLASSIFIER_MODEL_PATH)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Функція препроцесингу цифри (padding + grayscale)\n",
    "# ----------------------------------------------\n",
    "def preprocess_digit_for_classifier(img, target_size=(64, 64)):\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    img = cv2.equalizeHist(img)\n",
    "\n",
    "    # опціонально, якщо фон темний:\n",
    "    # _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    if h == 0 or w == 0:\n",
    "        return np.zeros((*target_size, 1), dtype=np.float32)\n",
    "\n",
    "    scale = min(target_size[0] / h, target_size[1] / w)\n",
    "    new_w, new_h = max(1, int(w * scale)), max(1, int(h * scale))\n",
    "    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    dw = target_size[1] - new_w\n",
    "    dh = target_size[0] - new_h\n",
    "    top, bottom = dh // 2, dh - dh // 2\n",
    "    left, right = dw // 2, dw - dw // 2\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
    "    padded = padded.astype('float32') / 255.0  # якщо немає Rescaling\n",
    "    padded = np.expand_dims(padded, axis=-1)\n",
    "    return padded\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Функція для класифікації одного кропа\n",
    "# ----------------------------------------------\n",
    "def classify_digit(crop):\n",
    "    processed = preprocess_digit_for_classifier(crop)\n",
    "    pred = classifier.predict(np.expand_dims(processed, axis=0), verbose=0)\n",
    "    return np.argmax(pred)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Читання ground truth з YOLO label файлу\n",
    "# ----------------------------------------------\n",
    "def load_ground_truth_from_txt(label_path):\n",
    "    digits = []\n",
    "    if not os.path.exists(label_path):\n",
    "        return digits\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                cls_id = int(float(parts[0]))\n",
    "                x_center = float(parts[1])\n",
    "                digits.append((x_center, cls_id))\n",
    "    # сортуємо за координатою X (YOLO дає нормалізовані)\n",
    "    digits.sort(key=lambda x: x[0])\n",
    "    gt_digits = [str(int(d[1])) for d in digits]\n",
    "    return gt_digits\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Обробка одного зображення\n",
    "# ----------------------------------------------\n",
    "def process_image(image_path, visualize=True):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"❌ Не вдалося завантажити: {image_path}\")\n",
    "        return None, None\n",
    "\n",
    "    # YOLO детекція\n",
    "    results = yolo_model.predict(image, verbose=False)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy() if len(results) > 0 else []\n",
    "\n",
    "    if len(boxes) == 0:\n",
    "        print(f\"⚠️ Нічого не знайдено на {os.path.basename(image_path)}\")\n",
    "        return [], image\n",
    "\n",
    "    boxes = sorted(boxes, key=lambda x: x[0])  # сортування за X\n",
    "\n",
    "    predicted_digits = []\n",
    "\n",
    "    for (x1, y1, x2, y2) in boxes:\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        if (x2 - x1) < 5 or (y2 - y1) < 5:\n",
    "            continue\n",
    "        crop = image[y1:y2, x1:x2]\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "        digit = classify_digit(crop)\n",
    "        predicted_digits.append(str(digit))\n",
    "\n",
    "        if visualize:\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0,255,0), 2)\n",
    "            cv2.putText(image, str(digit), (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "\n",
    "    if visualize:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Predicted: {''.join(predicted_digits)}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return predicted_digits, image\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Оцінка на тестових зображеннях\n",
    "# ----------------------------------------------\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for image_path in sorted(glob.glob(os.path.join(TEST_IMAGES_DIR, \"*.*\"))):\n",
    "    if not image_path.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        continue\n",
    "\n",
    "    file_id = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    label_path = os.path.join(TEST_LABELS_DIR, file_id + \".txt\")\n",
    "\n",
    "    gt_digits = load_ground_truth_from_txt(label_path)\n",
    "    predicted_digits, _ = process_image(image_path, visualize=False)\n",
    "\n",
    "    if not gt_digits:\n",
    "        print(f\"⚠️ Немає label для {file_id}\")\n",
    "        continue\n",
    "\n",
    "    # Порівняння\n",
    "    gt_str = \"\".join(gt_digits)\n",
    "    pred_str = \"\".join(predicted_digits)\n",
    "    match = (gt_str == pred_str)\n",
    "    if match:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    if total == 100:\n",
    "        break\n",
    "    print(f\"{file_id} | GT={gt_str} | Pred={pred_str} | {'✅' if match else '❌'}\")\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Фінальна точність\n",
    "# ----------------------------------------------\n",
    "if total > 0:\n",
    "    acc = correct / total * 100\n",
    "    print(f\"\\n✅ Accuracy: {acc:.2f}% ({correct}/{total})\")\n",
    "else:\n",
    "    print(\"⚠️ Не знайдено тестових зображень.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TF WSL)",
   "language": "python",
   "name": "tf-wsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
